# 对话记忆功能说明

## 📋 问题描述

**原始问题**：对话没有记忆，AI 无法记住之前说过的内容

**根本原因**：虽然代码将消息添加到了 ChatMemory，但在调用 LLM 时没有传递历史上下文。

## 🔧 修复方案

### 修复前的代码问题

```java
// ❌ 错误：只传递当前消息，没有历史上下文
aiReply = chatModel.chat(state.getUserInput());
```

这导致每次调用 LLM 时，AI 只能看到当前消息，看不到之前的对话历史。

### 修复后的实现

```java
// ✅ 正确：构建包含完整历史的上下文
List<ChatMessage> messages = memory.messages();  // 获取所有历史
String contextPrompt = buildContextPrompt(messages);  // 构建上下文
aiReply = chatModel.chat(contextPrompt);  // 带上下文调用
```

## 🎯 实现细节

### 1. 上下文构建方法

创建了 `buildContextPrompt()` 方法，将对话历史格式化为易读的上下文：

```java
private String buildContextPrompt(List<ChatMessage> messages) {
    StringBuilder context = new StringBuilder();
    
    for (ChatMessage message : messages) {
        if (message instanceof SystemMessage) {
            context.append("[系统]：").append(message.text()).append("\n\n");
        } else if (message instanceof UserMessage) {
            context.append("用户：").append(message.singleText()).append("\n\n");
        } else if (message instanceof AiMessage) {
            context.append("AI助手：").append(message.text()).append("\n\n");
        }
    }
    
    context.append("请根据以上对话历史，回复用户的最后一个问题。");
    return context.toString();
}
```

### 2. 上下文示例

对于多轮对话，构建的上下文类似：

```
[系统]：你是一位专业的医疗健康咨询助手...

用户：你好

AI助手：您好！我是 HealthCare AI 健康助手...

用户：我最近有点头疼

AI助手：关于头疼的问题，我需要了解更多信息...

用户：已经持续三天了

请根据以上对话历史，回复用户的最后一个问题。保持对话的连贯性和上下文一致性。
```

## ✨ 功能特性

### 1. 完整的对话历史
- ✅ 系统提示词（首轮对话时添加）
- ✅ 用户的所有历史消息
- ✅ AI 的所有历史回复
- ✅ 保持时间顺序

### 2. 会话管理
- ✅ 按 sessionId 隔离不同用户的对话
- ✅ 保留最近 10 轮对话（可配置）
- ✅ 自动清理过期会话（30分钟无活动）

### 3. 日志记录
```
发送消息到 LLM，历史消息数量: 5
构建的上下文长度: 1234 字符
LLM 回复成功（包含 5 条历史消息的上下文）
```

## 🧪 测试场景

### 测试 1：多轮对话连贯性

```
用户: 你好
AI: 您好！我是 HealthCare AI 健康助手...

用户: 我叫张三
AI: 张三您好！很高兴认识您...

用户: 我叫什么名字？
AI: 您之前告诉我您叫张三。  ← ✅ 记住了之前的信息
```

### 测试 2：医疗咨询上下文

```
用户: 我想咨询一下感冒的问题
AI: 好的，关于感冒，我可以帮您...

用户: 我已经咳嗽三天了
AI: 了解，您咳嗽三天了... [结合之前提到的感冒继续对话]

用户: 还需要注意什么？
AI: 除了咳嗽，对于您的感冒... ← ✅ 记住是感冒相关的对话
```

### 测试 3：会话隔离

```
# 会话 A (session_1)
用户: 我叫李四
AI: 李四您好...

# 会话 B (session_2) - 新会话
用户: 我叫什么名字？
AI: 抱歉，我不知道您的名字... ← ✅ 不同会话之间互不影响
```

## 📊 性能考虑

### 1. 上下文长度限制
- 当前配置：保留最近 10 轮对话
- 估算：约 10 轮 × 100 字/轮 = 1000 字
- 对于大多数 LLM 来说完全在可接受范围内

### 2. 内存使用
```yaml
healthcare:
  chat:
    memory:
      max-messages: 10  # 每个会话最多保留10条消息
```

可根据需求调整：
- 简单咨询：5-10 轮
- 复杂咨询：10-20 轮
- 长期追踪：20+ 轮（需要考虑持久化）

### 3. 会话清理
- 默认 30 分钟无活动自动清理
- 定时任务每 5 分钟检查一次
- 防止内存泄漏

## 🔍 调试技巧

### 查看对话历史数量
启用 DEBUG 日志级别：
```yaml
logging:
  level:
    com.yihu.agent.ai.graph.nodes.GeneralChatNode: DEBUG
```

日志输出：
```
DEBUG - 发送消息到 LLM，历史消息数量: 5
DEBUG - 构建的上下文长度: 1234 字符
```

### 手动清除会话
前端点击"新会话"按钮，会生成新的 sessionId，开始全新的对话。

### 检查内存
```java
int activeCount = chatMemoryService.getActiveSessionCount();
log.info("当前活跃会话数: {}", activeCount);
```

## ⚙️ 配置选项

### application.yml

```yaml
healthcare:
  chat:
    memory:
      # 每个会话保留的最大消息数
      max-messages: 10
    # 会话超时时间
    session-timeout: 30m
```

**建议值**:
- **快速咨询**: 5-10 轮
- **深度咨询**: 10-15 轮
- **长期跟踪**: 15-20 轮

## 🚀 下一步优化（可选）

### 1. 持久化存储
- 当前：内存存储（重启丢失）
- 未来：数据库存储（Redis/MySQL）

### 2. 智能摘要
- 当对话超过 N 轮时，自动生成摘要
- 只保留摘要 + 最近几轮对话
- 节省 token 成本

### 3. 用户画像
- 记录用户的健康档案
- 在每次对话时注入相关信息
- 提供更个性化的建议

## 📝 相关文件

| 文件 | 说明 |
|------|------|
| `GeneralChatNode.java` | 实现对话上下文构建 |
| `ChatMemoryService.java` | 管理会话记忆 |
| `HealthCareAgentService.java` | 协调服务调用 |
| `application.yml` | 配置参数 |

## ✅ 验证清单

- [x] 多轮对话能记住上下文
- [x] 不同会话之间隔离
- [x] 会话超时自动清理
- [x] 日志记录完整
- [x] 性能可接受

---

**最后更新**: 2025-11-05
**状态**: ✅ 已实现并测试通过

